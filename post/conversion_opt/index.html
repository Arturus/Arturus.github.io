<!DOCTYPE html>
<html lang="ru">
<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 3.0.0">
  <meta name="generator" content="Hugo 0.53" />
  <meta name="author" content="Артур Суилин">

  
  
  
  
    
  
  <meta name="description" content="При управлении онлайновыми рекламными кампаниями при подключении новых источников (объявлений, баннеров, SMM и т.п.) часто приходится решать проблему:
 С одной стороны, разумно подождать, пока источник не выдаст побольше переходов, посмотреть на конверсии, и тогда принимать решение, оставить его в рекламной кампании или отключить. Но если долго ждать, тогда рекламный бюджет будет зря расходоваться на неэффективные источники. С другой стороны, если сократить ожидание, можно случайно отключить источник, который на самом деле конверсионный, и наоборот, оставить неэффективный источник, случайно показавший высокую конверсию.">

  
  <link rel="alternate" hreflang="ru" href="https://suilin.ru/post/conversion_opt/">

  


  

  

  

  
  
  
  <meta name="theme-color" content="#086377">
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css" integrity="sha256-eSi1q2PG6J7g7ib17yAaWMcrr5GrtohYChqibrV7PBE=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.4.1/css/all.min.css" integrity="sha512-/RUbtHakVMJrg1ILtwvDIceb/cDkk97rWKvfnFSTOmNbytCyEylutDqeEr9adIBye3suD3RfcsXLOLBqYRW4gw==" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.css" integrity="sha256-ygkqlh3CYSUri3LhQxzdcm0n1EQvH2Y+U5S2idbLtxs=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css" crossorigin="anonymous">
      
    

    

    

  

  
  
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Fira+Sans+Condensed:400,400italic,700|PT+Mono|Fira+Sans|PT+Serif:400,400italic,700">
  

  <link rel="stylesheet" href="/styles.css">
  
  <link rel="stylesheet" href="/css/custom.css">
  

  
  
    <script>
      window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
      ga('create', 'UA-38480657-1', 'auto');
      
      ga('require', 'eventTracker');
      ga('require', 'outboundLinkTracker');
      ga('require', 'urlChangeTracker');
      ga('send', 'pageview');
    </script>
    <script async src="//www.google-analytics.com/analytics.js"></script>
    
    <script async src="https://cdnjs.cloudflare.com/ajax/libs/autotrack/2.4.1/autotrack.js" integrity="sha512-HUmooslVKj4m6OBu0OgzjXXr+QuFYy/k7eLI5jdeEy/F4RSgMn6XRWRGkFi5IFaFgy7uFTkegp3Z0XnJf3Jq+g==" crossorigin="anonymous"></script>
    
  
  

  
  <link rel="alternate" href="https://suilin.ru/index.xml" type="application/rss+xml" title="Артур Суилин">
  <link rel="feed" href="https://suilin.ru/index.xml" type="application/rss+xml" title="Артур Суилин">
  

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://suilin.ru/post/conversion_opt/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@asuilin">
  <meta property="twitter:creator" content="@asuilin">
  
  <meta property="og:site_name" content="Артур Суилин">
  <meta property="og:url" content="https://suilin.ru/post/conversion_opt/">
  <meta property="og:title" content="Конверсия и data science II. Оптимизируем неизвестность | Артур Суилин">
  <meta property="og:description" content="При управлении онлайновыми рекламными кампаниями при подключении новых источников (объявлений, баннеров, SMM и т.п.) часто приходится решать проблему:
 С одной стороны, разумно подождать, пока источник не выдаст побольше переходов, посмотреть на конверсии, и тогда принимать решение, оставить его в рекламной кампании или отключить. Но если долго ждать, тогда рекламный бюджет будет зря расходоваться на неэффективные источники. С другой стороны, если сократить ожидание, можно случайно отключить источник, который на самом деле конверсионный, и наоборот, оставить неэффективный источник, случайно показавший высокую конверсию.">
  
  
    
  <meta property="og:image" content="https://suilin.ru/img/me_sq.jpg">
  <meta property="og:locale" content="ru">
  
  <meta property="article:published_time" content="2018-12-21T00:00:00&#43;01:00">
  
  <meta property="article:modified_time" content="2018-12-21T00:00:00&#43;01:00">
  

  

  <meta property="og:type" content="article"/>
<meta name="yandex-verification" content="5753f991e1c3d96c" />
<meta name="google-site-verification" content="5sd_7MZqiS3rR-1B3f-FqUkrWEd92TYr9FNEGkFE14I" />

<script type="text/javascript" >
  (function (d, w, c) {
    (w[c] = w[c] || []).push(function() {
      try {
        w.yaCounter21550249 = new Ya.Metrika2({
          id:21550249,
          clickmap:true,
          trackLinks:true,
          accurateTrackBounce:true,
          webvisor:true
        });
      } catch(e) { }
    });

    var n = d.getElementsByTagName("script")[0],
      s = d.createElement("script"),
      f = function () { n.parentNode.insertBefore(s, n); };
    s.type = "text/javascript";
    s.async = true;
    s.src = "https://mc.yandex.ru/metrika/tag.js";

    if (w.opera == "[object Opera]") {
      d.addEventListener("DOMContentLoaded", f, false);
    } else { f(); }
  })(document, window, "yandex_metrika_callbacks2");
</script>
<noscript><div><img src="https://mc.yandex.ru/watch/21550249" style="position:absolute; left:-9999px;" alt="" /></div></noscript>



  <title>Конверсия и data science II. Оптимизируем неизвестность | Артур Суилин</title>

</head>
<body id="top" data-spy="scroll" data-target="#TableOfContents" data-offset="71" >

<nav class="navbar navbar-light fixed-top navbar-expand-lg py-0" id="navbar-main">
  <div class="container">

    
      <a class="navbar-brand" href="/">Артур Суилин</a>
      
      <button type="button" class="navbar-toggler" data-toggle="collapse"
              data-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Переключить навигацию">
        <span><i class="fas fa-bars"></i></span>
      </button>
      

    
    <div class="collapse navbar-collapse" id="navbar">

      
      
      <ul class="navbar-nav ml-auto">
        

        

        
        
        

        <li class="nav-item">
          <a class="nav-link" href="/">
            
            <span>Главная</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/post/">
            
            <span>Блог</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/project/">
            
            <span>Проекты</span>
            
          </a>
        </li>

        
        

        

        
        
        
          
        

        <li class="nav-item">
          <a class="nav-link" href="/#contact">
            
            <span>Контакты</span>
            
          </a>
        </li>

        
        

      

        

        
      </ul>

    </div>
  </div>
</nav>


<article class="article" itemscope itemtype="http://schema.org/Article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1 itemprop="name">Конверсия и data science II. Оптимизируем неизвестность</h1>

  
  <p class="page-subtitle">Или как выиграть у многоруких бандитов?</p>
  

  
    

<div class="article-metadata">

  
  
  <span itemscope itemprop="author" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Артур Суилин">
  </span>
  

  <span class="article-date">
    
    <meta content="2018-12-21 00:00:00 &#43;0100 CET" itemprop="datePublished">
    <time datetime="2018-12-21 00:00:00 &#43;0100 CET" itemprop="dateModified">
      21.12.2018
    </time>
  </span>
  <span itemscope itemprop="publisher" itemtype="http://schema.org/Person">
    <meta itemprop="name" content="Артур Суилин">
  </span>

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    22 min read
  </span>
  

  
  

  
  
  
  <span class="middot-divider"></span>
  <span class="article-categories">
    <i class="fas fa-folder"></i>
    
    <a href="/categories/internet-analytics/">Internet analytics</a>
    
  </span>
  
  

  
  

  

</div>

  
</div>



  <div class="article-container">

    <div class="article-style" itemprop="articleBody">
      

<p>При управлении онлайновыми рекламными кампаниями при подключении новых
источников (объявлений, баннеров, SMM и т.п.) часто приходится решать проблему:</p>

<ol>
<li>С одной стороны, разумно подождать, пока источник не выдаст побольше
переходов, посмотреть на конверсии, и тогда принимать решение, оставить его в рекламной
кампании или отключить.</li>
<li>Но если долго ждать, тогда рекламный бюджет будет зря расходоваться на
неэффективные источники.</li>
<li>С другой стороны, если сократить ожидание, можно случайно отключить источник,
который на самом деле конверсионный,
и наоборот, оставить неэффективный источник, случайно показавший
высокую конверсию.</li>
</ol>

<p>Очевидно, нужно найти некий баланс: с одной стороны, дать
источникам достаточно времени, чтобы проявить себя, с другой стороны вовремя отключать неэффективных.</p>

<p>Поиском такого баланса мы и займемся. Для этого будем тестировать
эффективность стратегий управления источниками на модели, имитирующей
поступление трафика и конверсии на реальном сайте.</p>

<h1 id="модель">Модель</h1>

<p>Мы будем моделировать рекламную кампанию, которая длится $T$ дней.
Средний объем трафика, приходящего на сайт &ndash; $V$ визитов в день,
этот трафик распределяется между $N$ источниками. У каждого источника есть вес,
$w_{i,t}$ обозначающий долю всего трафика, которая приходится на источник
в день $t$:</p>

<p>$$\sum_{i=1}^N w_{i,t} = 1, \;  t \in 1 \dots T$$</p>

<p>На старте у источников одинаковые равные веса $w_{i, 1}=\frac{1}{N}$.
Затем каждый день стратегия меняет вес источников на своё усмотрение.</p>

<p>Вес $w_{i,t}$ может быть нулевым, это означает, что источник отключен.</p>

<p>Каждый источник в соответствии со своим весом генерирует количество визитов
с матожиданием $\lambda_{i,t}$ (интенсивность визитов):
$$\lambda_{i,t} = w_{i,t} V$$</p>

<p>Но это среднее количество визитов, а реальное их количество
моделируется как
<a href="https://ru.wikipedia.org/wiki/%D0%9F%D1%80%D0%BE%D1%86%D0%B5%D1%81%D1%81_%D0%9F%D1%83%D0%B0%D1%81%D1%81%D0%BE%D0%BD%D0%B0" target="_blank">процесс Пуассона</a>
с интенсивностью $\lambda_{i,t}$. Тогда количество визитов $v_{i,t}$, которое выдаст источник в каждый конкретный день
$t$, сэмплируется из распределения Пуассона:
$$v_{i,t} \sim \mathrm{Pois}(\lambda_{i,t})$$
Таким образом моделируется ситуация из реальной жизни: далеко
не всегда можно управлять <em>точным</em> количеством переходов на сайт из источника.</p>

<p>Каждый источник имеет латентную конверсионность $\theta_i$ (т.е. это истинная конверсионность источника,
 которая проявится на большом количестве трафика).
Распределение
конверсионностей источников смоделируем логнормальным распределением:
$$\theta_i \sim \exp\left(\mathcal{N}(\mu, \sigma^2)\right)$$
Для наших экспериментов примем, что медианная конверсионность источников 1%:
$\mu = \ln(0.01)$ и $\sigma = 0.5$. Получится распределение,
похожее на то, что встречается на реальных сайтах:



<figure>

<img src="lognorm.png" width="384" />


</figure></p>

<div class="alert alert-note">
  <p>Логнормальное распределение несимметрично (длинный хвост справа), поэтому
для него матожидание (т.е. средняя конверсионность) и медиана будут немного отличаться:
$$\mathrm{E}=\exp\left(\mu + \frac{\sigma^2}{2}\right) \\<br />
\mathrm{Median}=\exp(\mu)$$
В используемом нами распределении средняя конверсионность будет $\approx 1.13\%$</p>

</div>


<p>Латентная конверсионность источника $\theta_i$ недоступна стратегии,
доступна только реализация конверсионности $r_{i,t}$:
$$c_{i,t} \sim \mathrm{Bin}(v_{i,t}, \theta_i) \\<br />
r_{i,t} = \frac{\sum_{j=1}^t c_{i,j}}{\sum_{j=1}^t v_{i,j}}$$
т.е. количество конверсий у источника в конкретный день $c_{i,t}$ сэмплируется из биномиального
распределения, а параметры биномиального распределения, в свою очередь,
тоже сэмплируются из своих распределений, описанных выше. Сэмплирование
количества визитов $v_{i,t}$ происходит каждый день, сэмплирование конверсионностей $\theta_i$
один раз перед стартом каждого эксперимента.</p>




<figure>

<img src="mab_model.png" alt="Принципиальная схема модели" width="515" />



<figcaption data-pre="Рис. " data-post=":" >
  
  <p>
    Принципиальная схема модели
    
    
    
  </p> 
</figcaption>

</figure>

<h2 id="параметры-по-умолчанию">Параметры по умолчанию</h2>

<p>Сведём вместе все значения параметров по умолчанию:</p>

<ul>
<li>$N=100$. В каждом эксперименте участвует 100 источников, из которых
будем отбирать лучших.</li>
<li>$T=90$. Рекламная кампания (т.е. один эксперимент) длится 90 дней.</li>
<li>$V=100$. Каждый день между источниками распределяется 100 визитов.
При таком объеме трафика на каждый источник приходится в среднем
всего <strong>один визит в день</strong>, и за всё время эксперимента произойдет в среднем
<strong>одна конверсия</strong> на источник! Очевидно, что выявление лучших источников при столь
малом объеме трафика это нетривиальная задача. Для некоторых
экспериментов будем использовать менее экстремальное значение $V=1000$</li>
<li>Конверсионность источников берётся из логнормального распределения
с параметрами $\mu=\ln(0.01), \sigma=0.5$, что соответствует средней
конверсионности $\approx 1.13\%$.</li>
<li>Результаты каждого эксперимента будут отличаться друг от друга
из за использования стохастических переменных, поэтому итоговый результат
будем рассчитывать, как среднее по 2000 повторений эксперимента.</li>
</ul>

<h2 id="цель-стратегий">Цель стратегий</h2>

<p>Стратегия в конце каждого дня (момент времени $t$) смотрит на накопленные результаты работы
источников (кол-во визитов, кол-во конверсий и вычисленная на их основе конверсионность) и принимает решение, какие
веса дать источникам на следующий день, т.е. на момент времени $t+1$.</p>

<p>Цель стратегии &ndash; получить максимальное кол-во конверсий за время рекламной кампании,
т.е. дать максимальный вес источникам с высокой конверсионностью
и минимальный вес всем остальным. В реальной жизни ёмкость источников ограничена,
поэтому существует дополнительное условие:
$w_{i} \leq w_i^{max}$</p>

<p>Каким должен быть максимальный вес $w_i^{max}$? Обычно источники
с высокой конверсионностью имеют меньшую ёмкость, так как по сути являются
узкими (и часто дорогими) сегментами аудитории. Чтобы отразить это в модели,
сделаем максимальный вес источника обратно пропорциональным его конверсионности:
$$w_{i}^{max} = \frac{k}{\theta_i} $$
где $\theta_i$ это латентная конверсионность, $k$ &ndash; коэффициент, регулирующий
среднюю ёмкость источников. Примем $k$ равным матожиданию конверсионности:
$$k=\mathrm{E}(\theta)$$
Тогда источник со &ldquo;средней&rdquo; конверсионностью будет иметь максимальный вес, равный
единице. Источник &ldquo;хуже среднего&rdquo; сможет быть единственным активным
источником для сайта, а источник &ldquo;лучше среднего&rdquo; &ndash; не сможет. Если конверсионность
источника в 2 раза выше средней, он сможет иметь максимум 50% трафика,
если в 4 раза выше средней &ndash; 25% трафика, и т.п.</p>

<p>В идеале к концу эксперимента должен остаться активным только топ
лучших источников. При используемом распределении конверсионностей в идеальный топ будет
входить в 80% случаев 3 источника и в 20% случаев 4 источника.</p>

<h2 id="оценка-стратегий">Оценка стратегий</h2>

<p>Эффективность стратегий оценивается по улучшению конверсионности по сравнению с baseline (0%)
и идеальным вариантом (100%).
За baseline принимается средняя конверсионность, которая будет, если вообще ничего
не делать и оставить все источники в равных долях, как они были на старте.
За идеальный вариант принимается максимальная конверсионность, которая была бы,
если с первого же дня оставить только лучшие источники и отключить все остальные.</p>

<p><em>Общее улучшение</em> &ndash; это то, как полученные результаты соотносятся с baseline и максимумом:
$$improvement=\frac{result-baseline}{maximum-baseline} \times 100\%$$
Улучшение рассчитывается для каждого дня отдельно, затем результат усредняется.
Если не получилось ничего улучшить по сравнению с baseline, улучшение будет 0%,
если наоборот с первого дня удалось достичь максимальной возможной конверсионности,
улучшение будет 100%. Реальное улучшение обычно будет между 0% и 100%
(но может быть и отрицательным, если результатом стратегии стало ухудшение
 конверсионности вместо улучшения).</p>

<p>Также интересно <em>финальное улучшение</em>, это то, где между baseline и максимумом
был результат в последний день рекламной кампании.</p>

<h1 id="наивная-стратегия">Наивная стратегия</h1>

<p>Начнём с самого простого, и протестируем наивную стратегию,
имитирующую традиционный способ управления источниками:</p>

<ol>
<li>Ждём, пока все источники не увидят в среднем $M$ визитов</li>
<li>Оставляем лучшие источники, отключаем все остальные.</li>
</ol>

<p>Каким должно быть $M$, т.е. сколько надо ждать &ndash; неизвестно, поэтому
попробуем разные значения:</p>




<figure>

<img src="naive_h.png" width="391" />


</figure>

<p>Видно, что при любых $M$ улучшение не поднимается выше 17%. Если
ждать недолго, то не успеем накопить достоверную информацию о конверсионности,
а если ждать дольше, то неэффективные источники отключатся только
в конце рекламной кампании. Естественно, при длительном ожидании финальное
улучшение будет высоким, но для всей рекламной кампании
важно именно общее улучшение.</p>

<p>Посмотрим на динамику конверсионности и
распределение улучшений при оптимальном $M=38$:



<figure>

<img src="naive.png" width="710" />


</figure></p>

<p>На левой диаграмме пунктирными линиями представлены baseline и максимальная
возможная конверсионность. График реальной конверсионности, являющийся результатом
работы стратегии &ndash; голубая линия с верхней и нижней границами, соответствующими доверительному интервалу 95%.
Общее улучшение соответствует
площади под этим графиком по отношению ко всей площади между зеленой
и оранжевой пунктирными линиями. Общее/финальное улучшения отображены
в заголовке диаграммы.</p>

<p>На правой диаграмме видно, что в части экспериментов улучшение было отрицательным, т.е. ожидания
в 38 дней явно недостаточно для получения достоверной информации о конверсионности.</p>

<h1 id="многорукие-бандиты">Многорукие бандиты</h1>

<p>Проблему, которую решают наши стратегии, можно сформулировать так:</p>

<blockquote>
<p>Найти баланс между а) исследованием конверсионности источников (<strong>exploration</strong>),
и б) использованием найденной конверсионности для оптимизации (<strong>exploitation</strong>), таким образом,
чтобы максимизировать выигрыш (в нашем случае количество конверсий).</p>
</blockquote>

<p>Эта проблема известна в более широком смысле, как проблема
<em>многорукого бандита</em>  ( <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit" target="_blank">multi-armed bandit</a>, MAB). Представим набор
игральных автоматов (слот-машин, также называемых однорукими бандитами), каждый из которых генерирует единичный выигрыш
с вероятностью $\theta_i$, неизвестной игроку. Задача игрока &ndash; за конечное время получить
максимальный выигрыш, т.е. поиграв на каждом бандите,
приблизительно определить его $\theta_i$  (exploration phase), и по результатам играть только на
&ldquo;прибыльных&rdquo; бандитах (exploitation phase).</p>




<figure>

<img src="bandits.jpg" width="672" />


</figure>

<p>В классической постановке MAB-проблемы игрок за один шаг взаимодействует (arm pull)
только с одним бандитом, и на основе полученного результата принимает решение
о выборе бандита для следующего шага. Такая постановка хороша для проведения
A/B тестов, но совершенно не подходит для управления источниками: представьте, если бы
мы запускали трафик на сайт по одному посетителю, и на основе того, сконвертировался
он или нет, решали, из какого источника должен придти следующий посетитель. Выглядит
малореалистично, не так ли?</p>

<p>В нашем случае:</p>

<ol>
<li>Игрок не имеет прямого контроля над тем, какой конкретный бандит
будет использоваться на каждом шаге, он может управлять только вероятностью игры на
каждом бандите (вероятности это веса источников $w_i$).</li>
<li>В каждом раунде происходит множество игр, в MAB терминологии это называется
*batch arm pulls*<sup><a href="#jun2016top" id="jun2016top_t">[1]</a></sup>. Текущая &ldquo;прибыльность&rdquo; бандитов вычисляется после окончания всего раунда.
В нашем случае один раунд это один день.</li>
</ol>

<p>Вообще MAB-стратегии очень хорошо изучены, но именно в классическом варианте
проблемы. Проблему в нашей постановке, как это ни удивительно, практически никто не исследовал.
Но ничто не мешает восполнить этот пробел и провести исследования самостоятельно.
Мы адаптируем несколько известных MAB-стратегий к нашей задаче и посмотрим на результаты.</p>

<h1 id="successivehalving">SuccessiveHalving</h1>

<p>Очень простая стратегия, не требующая сложных вычислений, и отлично подходящая для &ldquo;ручного&rdquo; применения.
Впервые описана в <sup><a href="#karnin2013almost" id="karnin2013almost_t">[2]</a></sup> под названием SequentalHalving.
Алгоритм:</p>

<ol>
<li>Так же как и в наивной стратегии, выбираем порог ожидания $M$ визитов</li>
<li>Когда порог достигнут, отключаем половину источников, которые показали
худшую конверсию, и удваиваем порог.</li>
<li>Повторяем шаг 2 до тех пор, пока не останется минимально возможное
количество источников (в нашем случае 3 или 4)</li>
</ol>

<p>Смысл стратегии в том, что по мере отключения явно плохих источников, у нас остаётся
больше ресурсов, чтобы исследовать потенциально хорошие источники.</p>

<p>


<figure>

<img src="succ_halving.png" alt="Результаты SuccessiveHalving  при оптимальном $M=11$." width="710" />



<figcaption data-pre="Рис. " data-post=":" >
  
  <p>
    Результаты SuccessiveHalving  при оптимальном $M=11$.
    
    
    
  </p> 
</figcaption>

</figure>
SuccessiveHalving демонстрирует результат примерно в два раза лучше по сравнению с наивной стратегией
 (улучшение <strong>33.7%</strong> против <strong>16.4%</strong>). Ухудшение вместо улучшения теперь
 почти не происходит, а финальное улучшение в отдельных случаях достигает 100%,
 т.е. стратегии удаётся выйти на <em>оптимальный</em> набор источников.
 Ступеньки на графике конверсионности образуются
 после каждого &ldquo;уполовинивания&rdquo; источников.</p>

<p>


<figure>

<img src="succ_halving_w.png" width="668" />


</figure>
Для этой и следующих стратегий будем визуализировать также динамику
изменения весов источников во времени, для трёх случайно выбранных экспериментов.
Видно, что сначала веса распределены поровну (exploration phase), затем
плохие источники постепенно отключаются, и их вес переходит к
перспективным источникам. В районе 40-го дня отключаются все плохие
источники, и происходит переход к чистому exploitation.</p>

<h1 id="varepsilon-decreasing">$\varepsilon$-decreasing</h1>

<p>Основная идея $\varepsilon$-стратегий это явное разделение ресурсов, отводимых
на exploration и exploitation. Выбирается число $0&lt;\varepsilon&lt;1$, на exploration
отводится доля ресурсов, равная $\varepsilon$, а на exploitation доля $1-\varepsilon$.
Наивная стратегия тоже является $\varepsilon$-стратегией, в терминологии MAB
она называется $\varepsilon$-first, т.к. сначала происходит 100% exploration (до момента
времени $t_M$, когда накопится $M$ визитов),
а затем 100% exploitation (до последнего дня $T$):
$$\varepsilon=\frac{t_M}{T}$$</p>

<p>Exploration и exploitation могут быть совмещены во времени, т.е.
доля трафика $1-\varepsilon$ отводится &ldquo;хорошим&rdquo; источникам, а остальной трафик
распределяется между всеми другими &ndash; такая стратегия будет называться $\varepsilon$-greedy.
Более оптимальны $\varepsilon$-decreasing стратегии<sup><a href="#cesa1998finite" id="cesa1998finite_t">[3]</a></sup>,<sup><a href="#auer2002finite" id="auer2002finite_t">[4]</a></sup>,
в которых $\varepsilon$ изменяется во времени:
сначала больше ресурсов отводится на exploration, но постепенно $\varepsilon$ уменьшается почти до нуля:
$$\varepsilon= \min\left(1, \frac{\varepsilon_0}{t}\right), \;  t \in 1,\dotsc,T$$
где $\varepsilon_0$ это базовое значение $\varepsilon$ (может быть больше единицы).
Для нашей модели оптимум $\varepsilon_0=3.5$:



<figure>

<img src="e-decreasing.png" width="710" />


</figure>
Результаты заметно улучшились по сравнению с SuccessiveHalving (<strong>38.2%</strong> против <strong>33.7%</strong>).
Это связано с тем, что $\varepsilon$-decreasing стратегия начинает exploitation уже на третий день и изменяет
веса источников ежедневно, а не скачками.



<figure>

<img src="e-decreasing-w.png" width="668" />


</figure>
На диаграммах с весами заметно характерное поведение: веса &ldquo;фоновых&rdquo;
источников плавно уменьшаются (градиент от фиолетового к чёрному),
в то же время стратегия пытается выявить лучшие источники, активно
переключаясь между кандидатами в течение первого месяца.</p>

<h1 id="softmax">Softmax</h1>

<p>В предыдущих стратегиях трафик распределялся поровну между лучшими источниками
(а также между активными &ldquo;худшими&rdquo;). Но почему бы распределять
трафик не поровну, а в соответствии с &ldquo;качеством&rdquo; источника, т.е.
его конверсионностью? Эту идею воплощает softmax стратегия:
$$w_i=\frac{e^{r_i/\tau}}{\sum_i e^{r_i/\tau}}$$
где $r_i$ это наблюдаемая конверсионность источника, $w_i$ &ndash; вес источника.
Правая часть формулы представляет собой <a href="https://ru.wikipedia.org/wiki/Softmax" target="_blank">softmax-функцию</a>,
аналогичную <a href="https://en.wikipedia.org/wiki/Boltzmann_distribution" target="_blank">распределению
Гиббса-Больцмана</a>,
поэтому компонент $\tau$ называют <em>температурой</em>. Конечно, никакого отношения
к статистической физике это стратегия не имеет, использование softmax функции это просто удобный
эмпирический способ выразить концепцию &ldquo;источник получает долю трафика, соответствующую его качеству&rdquo;.
Идея такого использования softmax предложена в <sup><a href="#luce2012individual" id="luce2012individual_t">[5]</a></sup>,
softmax-стратегия в применении к MAB проблемам проанализирована в <sup><a href="#cesa1998finite" id="cesa1998finite_t">[3]</a></sup>.</p>

<p>&ldquo;Температура&rdquo; обычно принимается обратно пропорциональной времени:
$$\tau=\frac{\tau_0}{t}$$



<figure>

<img src="softmax.png" width="710" />


</figure>
Результаты softmax стратегии лучше, чем $\varepsilon$-decreasing (<strong>39.2%</strong> против <strong>38.2%</strong>),
т.е. неравномерное распределение весов это работоспособная идея.
Видно, что стратегия пытается начинать активный exploration с первого же дня,
но часто принимает ошибочные решения и в следующие дни конверсия немного падает.



<figure>

<img src="softmax_w.png" width="668" />


</figure>
Стратегия очень оптимистична по поводу новых кандидатов: при появлении
нового &ldquo;фаворита&rdquo; почти весь вес сразу переносится на него,
но в следующие дни оптимизм уменьшается.</p>

<h1 id="байесовские-стратегии">Байесовские стратегии</h1>

<p>Всем стратегиям, которые мы уже протестировали, присущ один
недостаток: они сравнивают источники друг с другом только по их наблюдаемой
конверсионности. Такое сравнение предполагает, что наблюдаемая конверсионность содержит
одинаковое количество информации для всех источников, т.е. они стартуют в один и тот
же момент времени, выдают сопоставимое количество трафика, и рекламная
кампания завершается одномоментно, в заранее известный день.</p>

<p>В самом деле, нет смысла сравнивать конверсионность источника, который только
что стартовал (она скорее всего будет нулевой) с конверсионностью источника,
через который прошло уже несколько тысяч визитов &ndash; такое сравнение сразу
забракует &ldquo;молодой&rdquo; источник и стратегия будет работать неправильно.</p>

<p>Но условие &ldquo;одновременный старт, сопоставимый трафик, одновременное завершение&rdquo; далеко не всегда
выполнимо. Рекламные кампании могут включать в себя &ldquo;старые&rdquo; источники,
к ним в любой момент могут быть добавлены новые. Также постоянно происходит
ротация источников, неэффективные выводятся из кампании, вместо них добавляются свежие.
Момент завершения рекламной кампании малопредсказуем и зависит от её успешности, финансовых возможностей рекламодателя,
текущих цен на платный трафик, и т.д. Поэтому уже рассмотренные стратегии
будут хорошо работать только в тщательно контролируемых условиях. Для промышленного
применения нужны anytime-стратегии, способные адекватно учитывать уже накопленную
в источниках информацию и стартовать в любой момент, не привязываясь ко времени.</p>

<p>Очевидно, вместо наблюдаемой конверсионности такие стратегии должны
использовать количество визитов и количество конверсий.
И тут мы возвращаемся к байесовским методам работы с конверсией, описанным
в <a href="../conversion_numbers">предыдущей статье</a>.</p>

<h2 id="credible-bounds-racing">Credible Bounds Racing</h2>

<p>Вернёмся немного назад и вспомним картинку, на которой у источников есть
&ldquo;усы&rdquo;. Каждый ус обозначает верхнюю и нижнюю границы credible interval,
например для интервала 90% нижняя граница интерпретируется как
&ldquo;вероятность 5%, что конверсионность будет меньше этой границы&rdquo;,
верхняя соответственно &ldquo;вероятность 5%, что конверсионность окажется больше&rdquo;.



<figure>

<img src="forestplot.png" width="302" />


</figure>
Эти границы &ndash; всё, что нужно для работы простейшей байесовской стратегии. Алгоритм:</p>

<ol>
<li>Смотрим, есть ли источники, у которых верхняя граница интервала меньше, чем
нижняя граница любого другого источника (т.е. &ldquo;усы&rdquo; не перекрываются). На приведённой
выше диаграмме это источники A и B.</li>
<li>Если такие источники-аутсайдеры есть, значит они явно хуже одного из существующих источников, и их можно отключить.</li>
<li>На следующий день повторяем всё с пункта 1. Если по новым данным
видно, что источник был отключен зря (т.е. его верхняя граница
опять перекрывается со всеми остальными), включаем его обратно.</li>
</ol>

<p>При такой стратегии в конце концов останется один источник, у которого не
хватит трафика на весь сайт. Поэтому вводится дополнительное условие на
отключение: отключаемый источник не должен входить в топ &ldquo;самых перспективных&rdquo;.
Топ рассчитывается так: сортируем источники по верхней границе credible interval
(т.е. какую конверсионность они <em>могут</em> показать), и отбираем их в топ, начиная от самого
перспективного, пока не наберется общий максимальный вес больше единицы, т.е. пока топ не будет
способен сформировать весь трафик для сайта.</p>

<p>Такой же алгоритм используется при ручном управлении источниками
на основе диаграммы с &ldquo;усами&rdquo;. Собственно, приведённое описание алгоритма это всего
лишь формализация методики ручного управления.</p>

<p>Осталось только понять, какой должна быть оптимальная ширина credible interval, т.к.
при традиционной ширине 90% все &ldquo;усы&rdquo; будут перекрываться до последнего дня
рекламной кампании &ndash; у нас слишком мало визитов. Выясним оптимум экспериментальным путём:



<figure>

<img src="cb_racing_opt.png" width="390" />


</figure>
Оптимальный квантиль 0.34, что соответствует ширине интервала всего 32%.



<figure>

<img src="cb_racing.png" width="710" />


</figure>
Результат стратегии чуть хуже (на 0.2%), чем у предыдущего чемпиона (softmax).
Но при этом, как уже говорилось, эта стратегия более применима
для управления реальными источниками.
 


<figure>

<img src="cb_racing_w.png" width="710" />


</figure>
 Видно, что стратегия пытается отобрать оптимальные источники уже на второй день,
 но потом понимает, что поторопилась, и продолжает exploration. Если сделать
 ширину credible interval немного больше, эти артефакты исчезнут.</p>

<p>Посмотрим, каких результатов можно добиться (и при какой ширине правдоподобного интервала)
в других ситуациях:</p>

<ol>
<li>Более продолжительная рекламная кампания.</li>
<li>Больший объем трафика.



<figure>

<img src="cb_racing_h.png" width="708" />


</figure></li>
</ol>

<p>Получились похожие диаграммы. Если пересчитать продолжительность
рекламной кампании на левой диаграмме в эффективное количество визитов
на источник за всё время кампании, получим копию правой диаграммы. Т.е.
результаты стратегии и оптимальный credible interval зависят
только от среднего количества визитов на источник. Если это количество
увеличить до 900 (90 дней x 1000 визитов в день / 100 источников),
 можно получить улучшение <strong>&gt;70%</strong>,
а при увеличении до 9000 улучшение превышает <strong>90%</strong>, т.е. близко
к максимально возможной эффективности.</p>

<h2 id="probability-matching">Probability matching</h2>

<p>Если у нас есть все апостериорные распределения, почему бы не
ответить напрямую на вопрос, который нас на самом деле интересует? Нет, не о смысле
жизни, а более простой:</p>

<blockquote>
<p>Какова вероятность того, что $i$-ый источник имеет латентную конверсионность выше, чем все остальные?</p>
</blockquote>

<p>Если мы знаем эту вероятность, то логично установить веса источников
пропорциональными ей, и это будет оптимальным решением нашей задачи!
В самом деле, если вероятность нулевая, то источнику
надо дать нулевой вес, если вероятность 100%, то весь вес надо перенести
на этот лучший источник, если вероятности для двух источников 50:50,
надо дать им одинаковые веса по 50% трафика, и т.п. Сопоставление
вероятности оптимальности каждой &ldquo;руке бандита&rdquo; или в нашем случае источнику,
называется Probability Matching.<sup><a href="#scott2010modern" id="scott2010modern_t">[6]</a></sup>
$$w_i=\Pr(\theta_i=\max\{\theta_1,\dotsc,\theta_N\})$$
где $\theta_i$ это латентная конверсионность $i$-го источника. Это выражение
можно представить, как матожидание индикаторной функции:
$$\mathbb{I}_i(\theta)=\begin{cases}
      1 &amp;\text{if } \theta_i=\max\{\theta_1,\dotsc,\theta_N\}, \\<br />
      0 &amp;\text{otherwise }
      \end{cases}$$
$$w_i=\mathrm{E}\left(\mathbb{I}_i(\theta)\right)=\int \mathbb{I}_i(\theta)p(\theta)\mathrm{d}\theta$$
Апостериорное распределение переменной $\theta$ мы вычисляем через
сопряжённое бета распределение:
$$p(\theta_i)=\mathrm{Be}(\theta_i|\alpha_i,\beta_i) \\<br />
\alpha_i=\alpha_{prior} + S_i \\<br />
\beta_i=\beta_{prior} + N_i - S_i$$
где $S_i$ это количество наблюдаемых успехов (конверсий), $N_i$ - количество
наблюдений, т.е. визитов у $i$-го источника.</p>

<p>Вероятность того, что значение $\theta_j$ окажется меньше $\theta_i$, задаётся
через кумулятивную функцию бета распределения:
$$\Pr(\theta_j &lt; \theta_i) = \mathrm{Be_{CDF}}(\theta_i|\alpha_j,\beta_j)$$
Скомбинировав всё вместе, получаем:
$$w_i=\int_0^1 \mathrm{Be}(\theta_i|\alpha_i,\beta_i)\prod_{i \ne j} \mathrm{Be_{CDF}}(\theta_i|\alpha_j,\beta_j) \mathrm{d}\theta_i$$
Интеграл легко рассчитывается числовыми методами:</p>

<pre><code class="language-python">import numpy as np
from scipy.stats import beta
from scipy.integrate import quad

def opt_prob(α, β):
    def integrand(θ, i):
        logp = beta.logpdf(θ, α[i], β[i])
        logcdf = beta.logcdf(θ, α, β)
        logcdf[i] = 0
        return np.exp(logcdf.sum() + logp)
    return [quad(lambda θ: integrand(θ, i), 0, 1)[0] for i in range(len(α))]
</code></pre>

<p>Числовое интегрирование работает достаточно медленно, альтернативный и более универсальный способ
расчёта это сэмплирование из апостериорного распределения. Согласно
закону больших чисел, при большом количестве сэмплов среднее значение
выборки сойдется к матожиданию:
$$w_i=\lim\limits_{M \to \infty}\frac{1}{M} \sum_{m=1}^M \mathbb{I}_i(\theta_m) $$
Т.е. надо взять $M$ сэмплов, и для каждого источника вычислить,
в каком проценте сэмплов его значение конверсионности оказалось максимальным.
На практике достаточно 1K&ndash;8K сэмплов, для ускорения можно проводить
сэмплирование и часть расчёта на GPU.</p>




<figure>

<img src="mirror_c.jpg" width="515" />


</figure>

<p>Расчет через сэмплирование для классической MAB-задачи (когда не нужны
веса, а надо просто выбрать следующего бандита) известен, как
Thompson sampling.<sup><a href="#russo2018tutorial" id="russo2018tutorial_t">[7]</a></sup>
В этом случае достаточно единственного сэмпла,
и для следующего шага выбирается бандит, у которого в сэмпле оказалось максимальное значение вероятности.
Thompson sampling был предложен ещё в 1933 году, но тогда вычисления были
слишком дорогими, метод был забыт, и о нём вспомнили только в конце XX века.
Доказательство его оптимальности было получено в 1997 году.</p>

<p>Probability matching &ndash; оптимальная стратегия, всегда сходящаяся к выбору
лучших источников. Это схождение происходит достаточно быстро по меркам MAB-стратегий,
но слишком медленно для нас: probability matching не сделает
нулевым вес источника, пока не убедится в том, что он абсолютно безнадёжен.
Но чтобы убедиться в этом, требуется гораздо больше визитов, чем
имеющиеся у нас 90 на источник.</p>

<p>Вместо выбора гарантированно <em>лучших</em> источников
в отдалённом будущем, нам нужен возможно не самый оптимальный выбор
просто <em>хороших</em> источников в течение первых недель работы стратегии. Чтобы
сдвинуть баланс в сторону exploitation, добавим новый параметр $\rho$,
который будем называть жадностью:
$$w&rsquo;_i = w_i^\rho, \; \rho \geq 1 $$
где $w&rsquo;_i$ &ndash; эффективный вес $i$-го источника, который будет использовать
стратегия, $w_i$ &ndash; теоретически оптимальный вес, рассчитанный через
probability matching, $\rho$ &ndash; степень, в которую возводится теоретический
вес. Чем больше $\rho$, тем больше ресурсов переходит к уже известным &ldquo;хорошим&rdquo; источникам
и меньше ресурсов остаётся на exploration. Оптимальная жадность для
стандартных условий эксперимента: $\rho\approx7$. Посмотрим на результаты:</p>

<p>


<figure>

<img src="prob_match.png" width="710" />


</figure>
У нас новый чемпион! Улучшение <strong>41.1%</strong> это почти на 2 единицы
больше, чем предыдущий рекорд <strong>39.2%</strong>. Probability matching
действительно <em>оптимальная</em> стратегия.</p>

<p>


<figure>

<img src="prob_match_w.png" width="668" />


</figure>
Если стратегия не уверена в своём выборе, она не прекращает exploration
до самого последнего момента, в надежде добраться до истины. Если
выбор очевиден (попались явно хорошие источники), вес переходит к ним.
Exploration выглядит несколько хаотичным из за шума, вносимого
случайным сэмплированием, но на результаты этот шум не влияет.</p>

<p>Посмотрим, какие результаты покажет probability matching на других
объемах визитов:



<figure>

<img src="prob_match_v.png" width="708" />


</figure>
Результаты превосходны. Улучшение &gt;80% достигается сразу после
планки в 1000 визитов (т.е. 10 визитов в день на источник), а после
5000 визитов доступно улучшение &gt;90%!</p>

<p>Ещё очень важная деталь: эффективность стратегии слабо зависит от
выбора гиперпараметра $\rho$. В принципе на всём диапазоне протестированных
объемов одинаковое значение $\rho=3$ показало бы неплохие результаты.
Для сравнения можно посмотреть на аналогичные диаграммы для Credible
Bounds Racing: там правильный выбор ширины интервала играет решающую роль.</p>

<h2 id="неточное-априорное-распределение">Неточное априорное распределение</h2>

<p>Кроме $\rho$ есть еще один неявный гиперпараметр &ndash; априорное распределение конверсионностей.
Для тестирования стратегий я просто сгенерировал выборку 100 сэмплов из
используемого моделью логнормального
распределения и с помощью MLE вычислил параметры
соответствующего бета распределения. Понятно, что в реальной жизни
сэмплы из распределения латентных конверсионностей взять негде, разве что
попросить их у Господа, поэтому придётся использовать наблюдаемую
конверсионность, что негативно скажется на точности. Как неточное
определение параметров априорного распределения повлияет на результат? Давайте проверим.



<figure>

<img src="prob_match_priors.png" width="343" />


</figure></p>

<p>Для практических расчётов бета распределение удобно параметризовать не через $\alpha$
и $\beta$, а через конверсионность $r$ (играет роль матожидания)
 и эффективное количество визитов $v$ (играет роль дисперсии):
 $$\alpha = rv \\<br />
 \beta = (1-r)v$$
&ldquo;Правильные&rdquo; значения $\hat{r}$ и $\hat{v}$, полученные через MLE, отображены
на диаграмме зелёным пунктиром. Точка пересечения пунктирных линий &ndash;
параметры априорного распределения, которые использовались во всех предыдущих экспериментах.
Чтобы определить устойчивость стратегии к ошибкам в априорном распределении,
я провёл расчёты в диапазоне конверсионностей $[0.5\hat{r}, 2\hat{r}]$ и диапазоне
количества визитов $[\hat{v}/3,3\hat{v}]$, при объеме 1000 визитов в день.</p>

<p>На диаграмме видно, что стратегия не чувствительна к ошибкам
в эффективном количестве визитов, область оптимальных результатов
простирается от $v=100$ до $v=1100$. Ошибки в конверсионности более критичны.
На практике затруднения обычно вызывает как раз определение правильного
$v$, а промахнуться в два раза мимо конверсионности довольно сложно. При определении
$v$ лучше ошибиться в сторону меньшего количества визитов (т.е. большей дисперсии):
видно, что область оптимальных результатов расширяется к низу.</p>

<h2 id="применимость-для-других-распределений-конверсионности">Применимость для других распределений конверсионности</h2>

<p>Посмотрим, как ведёт себя
probability matching при использовании распределений конверсионностей, отличных
от распределения по умолчанию (матожидание конверсии $1.13\%$, $\sigma=0.5$).
Возьмем диапазон средней конверсии от 0.2% до 5% и стандартного отклонения 0.25&ndash;1.5.
Примеры таких распределений приведены ниже:



<figure>

<img src="conv_samples.png" width="424" />


</figure></p>

<p>Стратегия работоспособна во всём диапазоне, но результаты, естественно,
различаются:



<figure>

<img src="prob_match_%d1%811.png" width="425" />


</figure>
С увеличением средней конверсионности эффективность стратегии растёт,
т.к. появляется больше информации о конверсиях. При увеличении дисперсии
эффективность также растёт, так как увеличивается различие между
&ldquo;плохими&rdquo; и &ldquo;хорошими&rdquo; источниками. Чем больше это различие, тем
раньше можно его выявить, и тем лучше результат. При благоприятных
условиях (высокая конверсионность + высокая дисперсия) стратегия
достигает улучшения &gt;80% (напомню, это результат для 100 визитов в день,
т.е. в среднем один (!) визит на источник). Если стратегия работает с
объемом 1000 визитов в день, результат ещё лучше:



<figure>

<img src="prob_match_%d1%812.png" width="425" />


</figure>
Белая область на диаграмме &ndash; это улучшение &gt;90%.</p>

<h2 id="нестационарная-конверсионность">Нестационарная конверсионность</h2>

<p>Во всех предыдущих экспериментах мы исходили из того, что латентная
конверсионность источников, единожды заданная на старте, не меняется в ходе эксперимента.
В реальной жизни этого никто не может обещать. Более того, стабильная
конверсионность источников будет скорее исключением, чем правилом. Сможет ли
probability matching справиться с этим?</p>

<p>Смоделируем нестационарность как геометрическое случайное блуждание латентной конверсионности
c Гауссовскими приращениями и возвратом к среднему:
$$\theta&rsquo;_0 = \ln(\theta_0) \\<br />
\mu_t = \eta(\theta&rsquo;_0 - \theta&rsquo;_t) \\<br />
\theta&rsquo;_{t+1} = \theta&rsquo;_t + \mathcal{N}(\mu_t, \sigma^2) \\<br />
\theta_{t+1} = \exp(\theta&rsquo;_{t+1}) $$
где $\theta_0$ &ndash; начальная конверсионность, $\eta$ &ndash; скорость возврата
к среднему, $\sigma$ &ndash; волатильность.
 Изменение конверсионности
в ходе эксперимента может выглядеть например так:



<figure>

<img src="volatility.png" width="397" />


</figure></p>

<p>Чтобы стратегия могла адаптироваться к нестационарности, научим её
&ldquo;забывать&rdquo; прошлое. Обычно суммарное количество конверсий к моменту
времени $t$ получается сложением конверсий за все предыдущие дни:
$$c_t = \sum_{i=1}^t c&rsquo;_i$$
где $c&rsquo;_i$ это количество конверсий в день $i$. Теперь модифицируем суммирование,
и будем домножать каждое предыдущее кол-во конверсий на коэффициент затухания, $\gamma$:
$$c_t = \gamma c_{t-1} + c&rsquo;_t, \; \gamma \leq 1 $$
Таким образом на момент времени $t$ от конверсий первого дня
останется часть, пропорциональная $\gamma^t$. Стратегия <em>забудет</em> часть
отдалённого прошлого. Такая же операция проделывается с визитами, в результате
на выходе получим эффективное количество визитов и конверсий, которое будет
меньше, чем просто сумма.</p>




<figure>

<img src="prob_match_drift.png" alt="Результаты работы probability matching c $\gamma=0.8$, $\rho=2.1$,  $N=1000$ (количество визитов в день увеличено, чтобы у стратегии оставались ресурсы на exploration)." width="710" />



<figcaption data-pre="Рис. " data-post=":" >
  
  <p>
    Результаты работы probability matching c $\gamma=0.8$, $\rho=2.1$,  $N=1000$ (количество визитов в день увеличено, чтобы у стратегии оставались ресурсы на exploration).
    
    
    
  </p> 
</figcaption>

</figure>

<p>Максимальная конверсионность (зелёный пунктир) постепенно увеличивается,
потому что используются относительные приращения конверсионности,
и для смещения вверх есть больше места, чем для
смещения вниз (снизу конверсионность ограничена нулём). Видно, что график
реальной конверсионности почти успевает за графиком максимальной, т.е.
стратегия видит изменения и адаптируется к ним. Также помогает
относительно небольшое $\rho$, стимулирующее exploration.</p>

<p>Для сравнения: получено улучшение <strong>65.7%</strong>, улучшение при работе без затухания ($\gamma=1$)
составит <strong>59%</strong>, улучшение при тех же условиях в стационарном режиме
(т.е. с неизменной конверсией) &ndash; около <strong>75%</strong>.</p>

<p>


<figure>

<img src="prob_match_drift_w.png" width="668" />


</figure>
На диаграмме весов видно, что стратегия регулярно переключается
между режимами exploration и exploitation, т.к. конверсионность
источников постепенно изменяется.</p>

<h1 id="итоги">Итоги</h1>

<p>Если пересчитать результаты работы стратегий в прирост количества конверсий
на сайте, Probability Matching даcт прирост около <strong>33%</strong> относительно
<em>оптимизированной</em> наивной стратегии,
CB Racing соответственно немного меньше. Учитывая, что в реальной
жизни источниками часто управляют хаотично и качество такого управления
не дотягивает даже до наивной стратегии, прирост может быть ещё выше.</p>

<p>У байесовских стратегий хорошие перспективы применения, учитывая то,
что они не обязаны непосредственно управлять источниками. Вычисленное
с помощью probability matching оптимальное количество трафика
для источников можно отображать
в отчётах просто в качестве подсказки &ldquo;как лучше распределить трафик&rdquo;.
Ну а CB Racing это не только стратегия, но и инструкция по использованию
&ldquo;усов&rdquo; &ndash; правдоподобных интервалов конверсионности.</p>




<figure>

<img src="33.jpg" width="387" />


</figure>

<p>Probability matching устойчив к ошибкам в подборе гиперпараметров, это тоже важно для практического применения.
Я протестировал
эту стратегию во всех режимах, со всеми возможными ошибками, на которые хватило фантазии,
и ни в одном их них не было серьезных сбоев.</p>

<p>Probability matching также легко расширяется для использования дополнительной
контекстной информации. В реальной жизни нам известно об источниках и о трафике,
который из них приходит, гораздо больше, чем просто количество конверсий.
Тип источника, рекламная система, поведение посетителей из источника на сайте,
просмотренные страницы, продолжительность визита, и т.д. &ndash; всю эту
информацию можно и нужно использовать для повышения точности прогноза.
Возможности здесь практически безграничны, т.к. можно сэмплировать
конверсионность не только из аналитически заданных распределений, но
и из моделей машинного обучения, включая многослойные нейросети<sup><a href="#collier2018deep" id="collier2018deep_t">[8]</a></sup>.</p>

<p>Естественно, область применения не ограничивается сайтами:
реклама мобильных приложений, игровая реклама, call tracking &ndash; стратегии
могут использоваться везде, где существует выбор между несколькими альтернативными
источниками пользователей/клиентов.</p>

<p>Код для работы с моделью и стратегиями, описанными в статье, выложен в GitHub:
<a href="https://github.com/Arturus/conv_simulator" target="_blank">https://github.com/Arturus/conv_simulator</a></p>

<p>Также в Google Colab доступен готовый для работы Notebook со стратегиями:
<a href="https://colab.research.google.com/github/Arturus/conv_simulator/blob/master/demo.ipynb" target="_blank">https://colab.research.google.com/github/Arturus/conv_simulator/blob/master/demo.ipynb</a></p>

<h2 id="допущения">Допущения</h2>

<p>Чтобы не переусложнять модель и не загромождать текст подробностями,
были сделаны некоторые допущения:</p>

<ul>
<li>Не учитывается сезонность, т.е. колебания объема трафика и конверсионности между
рабочими и выходными днями.</li>
<li>Стоимость трафика у всех источников принимается одинаковой. В реальной
жизни для коммерческих источников надо было бы учитывать не кол-во
конверсий на единицу трафика (конверсионность), а кол-во конверсий на
единицу потраченных средств (стоимость конверсии), или прибыль на единицу затрат (ROI).</li>
<li>Не учитываются отложенные конверсии, т.е. предполагается, что
конверсия совершается в течение суток, между обновлениями весов источников. Для сайтов
с &ldquo;медленной&rdquo; конверсией надо вводить поправки к наблюдаемому
числу конверсий.</li>
<li>Поддерживаются только модели атрибуции, сопоставляющие
конверсию с единственным источником (т.е. по первому или последнему переходу)</li>
</ul>

<hr style="margin-top: 3em;">
<h2>Источники</h2>
<ol>
  

  
  <li id="jun2016top">

    <span class="bib-title">Top arm identification in multi-armed bandits with batch arm pulls.</span>

     <a href="#jun2016top_t">^</a>
    <div class="bib-authors">
     
       K. Jun,
     
       K. Jamieson,
     
       R. Nowak,
     
       X. Zhu,
     
    2016.
    AISTATS.
     (pp. 139-148)
    </div>

  </li>
  
  

  
  <li id="karnin2013almost">

    <span class="bib-title">Almost optimal exploration in multi-armed bandits</span>

     <a href="#karnin2013almost_t">^</a>
    <div class="bib-authors">
     
       Z. Karnin,
     
       T. Koren,
     
       O. Somekh,
     
    2013.
    ICML.
     (pp. 1238-1246)
    </div>

  </li>
  
  

  
  <li id="cesa1998finite">

    <span class="bib-title">Finite-time regret bounds for the multiarmed bandit problem.</span>

     <a href="#cesa1998finite_t">^</a>
    <div class="bib-authors">
     
       N. Cesa-Bianchi,
     
       P. Fischer,
     
    1998.
    ICML.
     (pp. 100-108)
    </div>

  </li>
  
  

  
  <li id="auer2002finite">

    <span class="bib-title">Finite-time analysis of the multiarmed bandit problem</span>

     <a href="#auer2002finite_t">^</a>
    <div class="bib-authors">
     
       P. Auer,
     
       N. Cesa-Bianchi,
     
       P. Fischer,
     
    2002.
    Machine learning.
    47.2-3 (pp. 235-256)
    </div>

  </li>
  
  

  
  <li id="luce2012individual">

    <span class="bib-title">Individual choice behavior: A theoretical analysis</span>

     <a href="#luce2012individual_t">^</a>
    <div class="bib-authors">
     
       R. Luce,
     
    1959.
    
    
    </div>

  </li>
  
  

  
  <li id="scott2010modern">

    <span class="bib-title">A modern bayesian look at the multi-armed bandit</span>

     <a href="#scott2010modern_t">^</a>
    <div class="bib-authors">
     
       S. Scott,
     
    2010.
    Applied Stochastic Models in Business and Industry.
    26.6 (pp. 639-658)
    </div>

  </li>
  
  

  
  <li id="russo2018tutorial">

    <span class="bib-title">A tutorial on thompson sampling</span>

     <a href="#russo2018tutorial_t">^</a>
    <div class="bib-authors">
     
       D. Russo,
     
       B. Van Roy,
     
       A. Kazerouni,
     
       I. Osband,
     
       Z. Wen,
     
      
     
    2018.
    Foundations and Trends in Machine Learning.
    11.1 (pp. 1-96)
    </div>

  </li>
  
  

  
  <li id="collier2018deep">

    <span class="bib-title">Deep contextual multi-armed bandits</span>

    [<a href="https://arxiv.org/abs/1807.09809">arXiv</a>] <a href="#collier2018deep_t">^</a>
    <div class="bib-authors">
     
       M. Collier,
     
       H. Llorens,
     
    2018.
    
    
    </div>

  </li>
  
  
</ol>

    </div>

    


<div class="article-tags">
  
  <a class="badge badge-light" href="/tags/conversion/">Conversion</a>
  
  <a class="badge badge-light" href="/tags/mab/">MAB</a>
  
</div>



    






<div class="media author-card" itemscope itemtype="http://schema.org/Person">
  
  <img class="portrait mr-3" src="/img/me_sq.jpg" itemprop="image" alt="Avatar">
  
  <div class="media-body">
    <h5 class="card-title" itemprop="name"><a href="/">Артур Суилин</a></h5>
    <h6 class="card-subtitle">Data Scientist</h6>
    
    <ul class="network-icon" aria-hidden="true">
      
      
      
      
      
      
      <li>
        <a itemprop="sameAs" href="//www.linkedin.com/in/suilin-arthur-304b8219/" target="_blank" rel="noopener">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
      
      
      
      
      
      
      <li>
        <a itemprop="sameAs" href="//github.com/Arturus" target="_blank" rel="noopener">
          <i class="fab fa-github"></i>
        </a>
      </li>
      
      
      
      
      
      
      <li>
        <a itemprop="sameAs" href="//www.kaggle.com/asuilin" target="_blank" rel="noopener">
          <i class="fab fa-kaggle"></i>
        </a>
      </li>
      
      
      
      
      
      
      <li>
        <a itemprop="sameAs" href="//instagram.com/asuilin" target="_blank" rel="noopener">
          <i class="fab fa-instagram"></i>
        </a>
      </li>
      
    </ul>
  </div>
</div>




    
    
    <div class="article-widget">
      <div class="hr-light"></div>
      <h3>Related</h3>
      <ul>
        
        <li><a href="/post/conversion_numbers/">Конверсия и data science I. Как увидеть невидимое.</a></li>
        
      </ul>
    </div>
    

    
    <div class="article-widget">
      <div class="post-nav">
  
  <div class="post-nav-item">
    <div class="meta-nav">Next</div>
    <a href="https://suilin.ru/post/conversion_factors/" rel="next">Конверсия и data science III. Как отличить хорошее от плохого?</a>
  </div>
  
  
  <div class="post-nav-item">
    <div class="meta-nav">Previous</div>
    <a href="https://suilin.ru/post/conversion_numbers/" rel="prev">Конверсия и data science I. Как увидеть невидимое.</a>
  </div>
  
</div>

    </div>
    

    


  </div>
</article>

<div class="container">
  <footer class="site-footer">
  

  <p class="powered-by">
    &copy; 2015-2023 &middot; Артур Суилин &middot; 

    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" id="back_to_top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

</div>


<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

    

    
    
    
    
    <script src="/js/mathjax-config.500a6cbb2c0f345fcecc21b3116d6637aa78f1f11db8081ea581abe05390c2e8f3bbffe61be3cf0217baf785c40efceabe51050a4f007e69af94efd3643260e8.js" integrity="sha512-UApsuywPNF/OzCGzEW1mN6p48fEduAgepYGr4FOQwujzu//mG&#43;PPAhe694XEDvzqvlEFCk8AfmmvlO/TZDJg6A=="></script>
    

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js" integrity="sha512-+NqPlbbtM1QqiK8ZAo4Yrj2c4lNQoGv8P79DPtKzj++l5jnN39rHA/xsqn8zE9l0uSoxaCdrOgFs6yjyfbBxSg==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.3/imagesloaded.pkgd.min.js" integrity="sha512-umsR78NN0D23AzgoZ11K7raBD+R6hqKojyBZs1w8WvYlsI+QuKRGBx3LFCwhatzBunCjDuJpDHwxD13sLMbpRA==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.min.js" integrity="sha256-VsEqElsCHSGmnmHXGQzvoWjWwoznFSZc6hs7ARLRacQ=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.4/isotope.pkgd.min.js" integrity="sha512-VDBOIlDbuC4VWxGJNmuFRQ0Li0SKkDpmGyuhAG5LTDLd/dJ/S0WMVxriR2Y+CyPL5gzjpN4f/6iqWVBJlht0tQ==" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.2.5/jquery.fancybox.min.js" integrity="sha256-X5PoE3KU5l+JcX+w09p/wHl9AzK333C4hJ2I9S5mD4M=" crossorigin="anonymous"></script>

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js" integrity="sha256-/BfiIkHlHoVihZdc6TFuj7MmJ0TWcWsMXkeDFwhi0zw=" crossorigin="anonymous"></script>
        
        <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js"></script>
        
      

      
      
      <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-AMS_CHTML-full" integrity="sha256-GhM+5JHb6QUzOQPXSJLEWP7R73CbkisjzK5Eyij4U9w=" crossorigin="anonymous" async></script>
      
    

    <script src="/js/hugo-academic.js"></script>
    

    
    

    
    
    

    
    
    <script>hljs.initHighlightingOnLoad();</script>
    

    

    
    

    

    
    

    
    
    <script>
      
      window.lazyLoadOptions = {elements_selector: ".lazy"};
    </script>
    <script async src="https://cdn.jsdelivr.net/npm/intersection-observer@0.5.1/intersection-observer.js"></script>
    <script async src="https://cdn.jsdelivr.net/npm/vanilla-lazyload@11.0.5/dist/lazyload.min.js"></script>

  </body>
</html>

